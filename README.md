# ğŸš¢ Titanic Survival Prediction using Random Forest ğŸŒ²

## ğŸ“Œ Project Overview
This project analyzes the famous Titanic dataset and applies a **Random Forest** ğŸŒ³ machine learning algorithm to predict passenger survival. The goal is to uncover key factors influencing who survived and who didn't aboard the Titanic.

---

## ğŸ“Š Dataset Overview
The Titanic dataset contains information on **891 passengers**, including their age, gender, ticket class, fare paid, cabin allocation, and family members onboard. The dataset contains some missing values (particularly for `Age`, `Cabin`, and `Embarked`), which were carefully handled during preprocessing. ğŸ› ï¸

---

## ğŸ” Exploratory Data Analysis (EDA)
Several key questions were addressed through data analysis:

1. **ğŸ‘« Gender Distribution:** Were there more male or female passengers onboard?
2. **ğŸ’³ Class vs. Survival:** Did passenger class affect survival chances?
3. **ğŸ‘¶ Age Distribution:** What age groups were most common on the ship?
4. **ğŸ  Cabin Assignments:** How were passengers distributed across cabins?
5. **âš“ Ports of Embarkation:** From which ports (Cherbourg, Queenstown, Southampton) did most passengers board?
6. **ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Family Impact:** Did traveling alone or with family influence survival rates?

---

## ğŸ¤– Machine Learning Approach
- **Algorithm:** Random Forest Classifier ğŸŒ²
- **Feature Engineering:** Managed missing values, performed label encoding for categorical variables (like gender and embarkation port), and engineered new features such as family size. ğŸ§©
- **Model Evaluation:** Assessed using accuracy, precision, recall, and confusion matrix. ğŸ“ˆ

---

## ğŸ› ï¸ Tech Stack
- **Programming Language:** Python ğŸ  
- **Libraries:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn ğŸ“š  
- **Data Handling:** CSV files and Excel ğŸ“‚  
- **Visualization:** Matplotlib and Seaborn ğŸ“Š  

---

## ğŸ¯ Results
The Random Forest model identified critical survival factors, including passenger class (`Pclass`), gender (`Sex`), age, family size, and embarkation port. The final model achieved an accuracy of approximately **80%**, showing solid predictive performance. âœ…  

Detailed metrics and visualizations are provided within the project notebook.

---

## ğŸš€ Future Improvements
- **Hyperparameter Tuning:** Optimize Random Forest parameters to potentially boost accuracy. âš™ï¸
- **Feature Engineering:** Investigate new or refined features for improved predictive power. ğŸ”§
- **Alternative Models:** Evaluate models like XGBoost or Gradient Boosting for comparative analysis and performance improvements. ğŸ”

---
